## LLM Extended Memory Framework
The LLM Extended Memory Framework is an open-source project designed to enhance the memory capabilities of large language models like OpenAI's GPT-series. By implementing an efficient encoding, storage, indexing, recall, and decoding system, this project aims to overcome the memory limitations associated with typical input+context character limits.

## Features
- **Memory Encoder**: Compact semantic representations of conversation and context
- **External Memory Storage**: Support for storing data on various storage media (local files, databases, etc.)
- **Indexing System**: Efficient retrieval of required information based on keyword, topic, or semantic searches
- **Memory Recall**: Seamless retrieval and reintegration of essential data into ongoing tasks or conversations
- **Memory Decoder**: Reconstruction of original data from their encoded representations for LLM model compatibility
- **Integration with LLM**: Working in conjunction with LLM models for improved performance in complex tasks and long conversations
